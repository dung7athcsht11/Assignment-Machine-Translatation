{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz7WWZlBjA3a",
        "outputId": "96c28912-224a-4d20-8d08-e5e25f673f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/NMT_Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Tạo thư mục làm việc\n",
        "import os\n",
        "base_path = '/content/drive/MyDrive/NMT_Project'\n",
        "if not os.path.exists(base_path):\n",
        "    os.makedirs(base_path)\n",
        "%cd {base_path}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvi\n",
        "!pip install subword-nmt\n",
        "!pip install tensorflow-text\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ingj3RSUjVea",
        "outputId": "5e19a683-e2dd-4220-bf22-c0f2f3ac12c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from pyvi) (1.6.1)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pyvi) (3.6.0)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\n",
            "Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0\n",
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting mock (from subword-nmt)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from subword-nmt) (4.67.1)\n",
            "Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Downloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: mock, subword-nmt\n",
            "Successfully installed mock-5.2.0 subword-nmt-0.3.8\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-text) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19.0->tensorflow-text) (0.1.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvi import ViTokenizer\n",
        "\n",
        "def preprocess_data(en_path, vi_path, limit=None):\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "\n",
        "    with open(en_path, 'r', encoding='utf-8') as f_en, \\\n",
        "         open(vi_path, 'r', encoding='utf-8') as f_vi:\n",
        "\n",
        "        lines_en = f_en.readlines()\n",
        "        lines_vi = f_vi.readlines()\n",
        "        if limit:\n",
        "            lines_en = lines_en[:limit]\n",
        "            lines_vi = lines_vi[:limit]\n",
        "\n",
        "        for en, vi in zip(lines_en, lines_vi):\n",
        "            en_clean = en.strip().lower()\n",
        "\n",
        "            vi_tokenized = ViTokenizer.tokenize(vi.strip())\n",
        "            vi_clean = f\"<start> {vi_tokenized} <end>\"\n",
        "\n",
        "            input_texts.append(en_clean)\n",
        "            target_texts.append(vi_clean)\n",
        "\n",
        "    return input_texts, target_texts\n",
        "input_docs, target_docs = preprocess_data('train.en.txt', 'train.vi.txt')\n",
        "\n",
        "\n",
        "print(f\"Số lượng câu huấn luyện: {len(input_docs)}\")\n",
        "print(f\"Ví dụ Input (EN): {input_docs[0]}\")\n",
        "print(f\"Ví dụ Target (VI): {target_docs[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncem0t2fjhmA",
        "outputId": "02f582a1-6b06-4eea-971a-f58203ca9cc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng câu huấn luyện: 133317\n",
            "Ví dụ Input (EN): rachel pike : the science behind a climate headline\n",
            "Ví dụ Target (VI): <start> Khoa_học đằng sau một tiêu_đề về khí_hậu <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    tf.compat.v1.enable_eager_execution()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = 10000\n",
        "SEQUENCE_LENGTH = 40\n",
        "EMBEDDING_DIM = 128\n",
        "LATENT_DIM = 256\n",
        "\n",
        "print(\"Đang chuyển đổi dữ liệu sang NumPy...\")\n",
        "input_arr = np.array(input_docs, dtype=object) # dtype=object để chứa chuỗi\n",
        "target_arr = np.array(target_docs, dtype=object)\n",
        "\n",
        "#vector hóa cho Tiếng Anh\n",
        "source_vectorization = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=SEQUENCE_LENGTH,\n",
        ")\n",
        "print(\"Đang học từ vựng tiếng Anh (Adapt)...\")\n",
        "source_vectorization.adapt(input_arr)\n",
        "\n",
        "#vector hóa cho Tiếng Việt\n",
        "target_vectorization = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=SEQUENCE_LENGTH + 1,\n",
        ")\n",
        "print(\"Đang học từ vựng tiếng Việt (Adapt)...\")\n",
        "target_vectorization.adapt(target_arr)\n",
        "\n",
        "print(\"Đã tạo xong bộ từ điển thành công!\")\n",
        "\n",
        "#Chuẩn bị dữ liệu train format TF (Pipeline)\n",
        "def format_dataset(eng, vi):\n",
        "    eng = source_vectorization(eng)\n",
        "    vi = target_vectorization(vi)\n",
        "    return ({\n",
        "        \"encoder_inputs\": eng,\n",
        "        \"decoder_inputs\": vi[:, :-1],\n",
        "    }, vi[:, 1:])\n",
        "\n",
        "def make_dataset(input_texts, target_texts):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_texts, target_texts))\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "print(\"Đang tạo luồng dữ liệu training...\")\n",
        "train_ds = make_dataset(input_docs, target_docs)\n",
        "print(\"Sẵn sàng để Train!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F84GujzQjlfP",
        "outputId": "d00f6c69-9471-4d6a-cbb8-b8254a4f13f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang chuyển đổi dữ liệu sang NumPy...\n",
            "Đang học từ vựng tiếng Anh (Adapt)...\n",
            "Đang học từ vựng tiếng Việt (Adapt)...\n",
            "Đã tạo xong bộ từ điển thành công!\n",
            "Đang tạo luồng dữ liệu training...\n",
            "Sẵn sàng để Train!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "class Decoder(Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = LSTM(dec_units, return_sequences=True, return_state=True)\n",
        "        self.attention = Attention()\n",
        "        # Projection để enc_output -> dec_units\n",
        "        self.enc_proj = Dense(dec_units)\n",
        "        self.fc = Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, enc_output, state_h, state_c):\n",
        "        x = self.embedding(x)\n",
        "        enc_proj = self.enc_proj(enc_output)  # shape = dec_units\n",
        "        # Attention\n",
        "        context_vector = self.attention([x, enc_proj])\n",
        "        x = tf.concat([context_vector, x], axis=-1)\n",
        "        output, h, c = self.lstm(x, initial_state=[state_h, state_c])\n",
        "        x = self.fc(output)\n",
        "        return x, h, c\n"
      ],
      "metadata": {
        "id": "tzpI5H3kj4AI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(VOCAB_SIZE, EMBEDDING_DIM, LATENT_DIM)\n",
        "decoder = Decoder(VOCAB_SIZE, EMBEDDING_DIM, LATENT_DIM, LATENT_DIM)\n",
        "\n",
        "\n",
        "# Loss function\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n"
      ],
      "metadata": {
        "id": "LsrGMoUFt954"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(batch_input, batch_target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_h, enc_c = encoder(batch_input['encoder_inputs'])\n",
        "        dec_input = batch_input['decoder_inputs']\n",
        "        dec_target = batch_target\n",
        "\n",
        "        predictions, _, _ = decoder(dec_input, enc_output, enc_h, enc_c)\n",
        "        loss = loss_function(dec_target, predictions)\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "Au0IkNHTuAWP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5  # thử trước để test\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(train_ds):\n",
        "        batch_loss = train_step(inp, targ)\n",
        "        total_loss += batch_loss\n",
        "        if batch % 50 == 0:\n",
        "            print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "    print(f'Epoch {epoch+1} Loss {total_loss/ (batch+1):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "QMD400TEuCYH",
        "outputId": "ed3f3e5d-f008-4680-ffe2-788216942f47"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/tmp/ipython-input-2633100946.py\", line 8, in train_step  *\n        predictions, _, _ = decoder(dec_input, enc_output, enc_h, enc_c)\n    File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/ipython-input-1885996051.py\", line 17, in call\n        context_vector = self.attention([x, enc_proj])\n\n    ValueError: Exception encountered when calling Attention.call().\n    \n    \u001b[1mDimensions must be equal, but are 128 and 256 for '{{node decoder_1_1/attention_1_1/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false, grad_x=false, grad_y=false](decoder_1_1/embedding_8_1/GatherV2, decoder_1_1/attention_1_1/transpose)' with input shapes: [64,40,128], [64,256,40].\u001b[0m\n    \n    Arguments received by Attention.call():\n      • inputs=['tf.Tensor(shape=(64, 40, 128), dtype=float32)', 'tf.Tensor(shape=(64, 40, 256), dtype=float32)']\n      • mask=['None', 'None']\n      • training=False\n      • return_attention_scores=False\n      • use_causal_mask=False\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4118672577.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileniok1ugd.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(batch_input, batch_target)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mdec_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1885996051.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, state_h, state_c)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0menc_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape = dec_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_proj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipython-input-2633100946.py\", line 8, in train_step  *\n        predictions, _, _ = decoder(dec_input, enc_output, enc_h, enc_c)\n    File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/ipython-input-1885996051.py\", line 17, in call\n        context_vector = self.attention([x, enc_proj])\n\n    ValueError: Exception encountered when calling Attention.call().\n    \n    \u001b[1mDimensions must be equal, but are 128 and 256 for '{{node decoder_1_1/attention_1_1/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false, grad_x=false, grad_y=false](decoder_1_1/embedding_8_1/GatherV2, decoder_1_1/attention_1_1/transpose)' with input shapes: [64,40,128], [64,256,40].\u001b[0m\n    \n    Arguments received by Attention.call():\n      • inputs=['tf.Tensor(shape=(64, 40, 128), dtype=float32)', 'tf.Tensor(shape=(64, 40, 256), dtype=float32)']\n      • mask=['None', 'None']\n      • training=False\n      • return_attention_scores=False\n      • use_causal_mask=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "VOCAB_SIZE = 10000\n",
        "SEQUENCE_LENGTH = 40\n",
        "EMBEDDING_DIM = 128\n",
        "LATENT_DIM = 256\n",
        "\n",
        "#  Encoder\n",
        "encoder_inputs = Input(shape=(SEQUENCE_LENGTH,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "\n",
        "\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = layers.LSTM(\n",
        "    LATENT_DIM,\n",
        "    return_state=True,\n",
        "    recurrent_dropout=0.1\n",
        ")(x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(SEQUENCE_LENGTH,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, mask_zero=True)(decoder_inputs)\n",
        "\n",
        "decoder_lstm = layers.LSTM(\n",
        "    LATENT_DIM,\n",
        "    return_sequences=True,\n",
        "    return_state=True,\n",
        "    recurrent_dropout=0.1\n",
        ")\n",
        "decoder_outputs, _, _ = decoder_lstm(x, initial_state=encoder_states)\n",
        "\n",
        "# Output Layer\n",
        "decoder_dense = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Compile Model\n",
        "model_baseline = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Dùng Adam optimizer\n",
        "model_baseline.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model_baseline.summary()\n",
        "\n",
        "print(\" Bắt đầu Training\")\n",
        "# Training\n",
        "history = model_baseline.fit(train_ds, epochs=10)\n",
        "\n",
        "model_baseline.save('model_baseline.keras')\n",
        "print(\"Đã lưu model thành công!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jgy_-rtaujx3",
        "outputId": "ec79e77d-a537-4940-eb84-fcfc24a2c7d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_13        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_14        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ embedding_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m2,570,000\u001b[0m │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_13        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_14        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,000</span> │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,918,480\u001b[0m (22.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,918,480</span> (22.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,918,480\u001b[0m (22.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,918,480</span> (22.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bắt đầu Training\n",
            "Epoch 1/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 282ms/step - accuracy: 0.0996 - loss: 5.9469\n",
            "Epoch 2/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 281ms/step - accuracy: 0.1123 - loss: 4.8322\n",
            "Epoch 3/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 278ms/step - accuracy: 0.1332 - loss: 4.3823\n",
            "Epoch 4/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 278ms/step - accuracy: 0.1452 - loss: 4.0762\n",
            "Epoch 5/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 277ms/step - accuracy: 0.1533 - loss: 3.8579\n",
            "Epoch 6/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 274ms/step - accuracy: 0.1602 - loss: 3.6874\n",
            "Epoch 7/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 271ms/step - accuracy: 0.1657 - loss: 3.5489\n",
            "Epoch 8/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 269ms/step - accuracy: 0.1705 - loss: 3.4322\n",
            "Epoch 9/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 270ms/step - accuracy: 0.1748 - loss: 3.3315\n",
            "Epoch 10/10\n",
            "\u001b[1m2084/2084\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 271ms/step - accuracy: 0.1790 - loss: 3.2424\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/IWSLT15/model_baseline.keras'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-330777783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_baseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmodel_baseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/IWSLT15/model_baseline.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Đã lưu model thành công!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, weights_format, zipped)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_filepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0m_save_model_to_fileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/IWSLT15/model_baseline.keras'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_baseline.save('model_baseline.keras')"
      ],
      "metadata": {
        "id": "Qqv_a3aRK7Wj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "print(\"đang tải data test\")\n",
        "test_input_docs, test_target_docs = preprocess_data('tst2013.en.txt',  'tst2013.vi.txt')\n",
        "print(f\"Số lượng câu test: {len(test_input_docs)}\")\n",
        "\n",
        "test_ds = make_dataset(test_input_docs, test_target_docs)\n",
        "\n",
        "#Đánh giá sơ bộ (Loss & Accuracy)\n",
        "print(\"Đánh giá toàn tập test\")\n",
        "results = model_baseline.evaluate(test_ds)\n",
        "print(f\"Test Loss: {results[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {results[1]:.4f}\")\n",
        "\n",
        "vi_vocab = target_vectorization.get_vocabulary()\n",
        "vi_index_lookup = dict(zip(range(len(vi_vocab)), vi_vocab))\n",
        "max_decoded_sentence_length = SEQUENCE_LENGTH\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"<start>\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = model_baseline.predict([tokenized_input, tokenized_target], verbose=0)\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = vi_index_lookup[sampled_token_index]\n",
        "\n",
        "        if sampled_token == \"<end>\":\n",
        "            break\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "    return decoded_sentence.replace(\"<start>\", \"\").strip()\n",
        "\n",
        "#  Tính điểm BLEU\n",
        "print(\"\\n Tính điểm BLEU\")\n",
        "num_samples =  50\n",
        "total_bleu = 0\n",
        "\n",
        "random_indices = random.sample(range(len(test_input_docs)), num_samples)\n",
        "\n",
        "for idx in random_indices:\n",
        "    input_sen = test_input_docs[idx]\n",
        "    target_sen = test_target_docs[idx].replace(\"<start>\", \"\").replace(\"<end>\", \"\").strip()\n",
        "\n",
        "    predicted_sen = decode_sequence(input_sen)\n",
        "\n",
        "    ref = [target_sen.split()]\n",
        "    cand = predicted_sen.split()\n",
        "    score = sentence_bleu(ref, cand, smoothing_function=SmoothingFunction().method1)\n",
        "    total_bleu += score\n",
        "\n",
        "    print(f\"\\n Input (En):  {input_sen}\")\n",
        "    print(f\" Target (Vi): {target_sen}\")\n",
        "    print(f\" Model Dịch:  {predicted_sen}\")\n",
        "    print(f\" BLEU Score:  {score:.4f}\")\n",
        "\n",
        "avg_bleu = total_bleu / num_samples\n",
        "print(f\"\\n------------------------------------------------\")\n",
        "print(f\"ĐIỂM BLEU TRUNG BÌNH ({num_samples} mẫu): {avg_bleu:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL0-ioYRvDtn",
        "outputId": "eed6c411-2e37-4761-93e9-cb9b4bda9ee9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "đang tải data test\n",
            "Số lượng câu test: 1268\n",
            "Đánh giá toàn tập test\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.1693 - loss: 3.8362\n",
            "Test Loss: 3.7608\n",
            "Test Accuracy: 0.1715\n",
            "\n",
            " Tính điểm BLEU\n",
            "\n",
            " Input (En):  these north koreans were not so lucky .\n",
            " Target (Vi): Nhưng những người Bắc Triều_Tiên này thì không được may_mắn như_vậy .\n",
            " Model Dịch:  những con này không có [UNK] [UNK] end  end end end end end end end end end end end end end tấtcả end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0062\n",
            "\n",
            " Input (En):  who will he become because someone took a stand and made a difference in his life ?\n",
            " Target (Vi): Em sẽ trở_thành người thế_nào nếu có ai đó đứng lên và thay_đổi cuộc_đời em ?\n",
            " Model Dịch:  ai đó sẽ trởthành một người đànông một người đànông và một người khác và đó là một cuộcsống end  end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0126\n",
            "\n",
            " Input (En):  so i got an old car battery , an indicator box . it &apos;s a small device found in a motorcycle , and it helps motorists when they want to turn right or left . it blinks .\n",
            " Target (Vi): Thế nên tôi đã lấy một bình ắc - quy xe ô_tô cũ một hộp đồng_hồ đo . Nó là một thiết_bị nhỏ được tìm thấy ở xe mô_tô và nó giúp người lái mô_tô ra_hiệu khi họ muốn rẽ trái hay rẽ phải . Nó chớp nháy .\n",
            " Model Dịch:  vậy là một chiếc xe ôtô có một chiếc xe ôtô [UNK] [UNK] một chiếc xe như một chiếc xe và khi nó có một chiếc xe và nếu bạn cóthể làm nó như thế này end  đó end\n",
            " BLEU Score:  0.0113\n",
            "\n",
            " Input (En):  now , we were lucky with our hand-cleaning .\n",
            " Target (Vi): Chúng_tôi đã gặp may với việc lau ảnh bằng tay .\n",
            " Model Dịch:  và chúngtôi đã maymắn được với những người [UNK] end  end end end end end end end end quot quot quot quot quot quot quot end end end cả end end end end tấtcả end tấtcả end end end\n",
            " BLEU Score:  0.0056\n",
            "\n",
            " Input (En):  first you get one stone , then several more , and more and more and more and more , and then they -- well , i will not do that .\n",
            " Target (Vi): Trước_tiên bạn được một hòn đá , rồi nhiều hơn , rồi ngày_càng nhiều , nhiều , nhiều , nhiều hơn nữa , và rồi chúng - - kìa , tôi sẽ không làm như vậy đâu .\n",
            " Model Dịch:  Đầutiên là lần đầutiên khi bạn đi và vài năm nữa và tôi sẽ thấy nhiều hơn và tôi sẽ không có nhiều hơn nữa end  này end đó end đó end đó quot quot quot quot quot quot\n",
            " BLEU Score:  0.0474\n",
            "\n",
            " Input (En):  takes about $ 300 , by the way , in the neurologist &apos;s clinic to do it .\n",
            " Target (Vi): Chỉ tất khoảng $ 300 mà thôi , Để làm xét_nghiệm này tại phòng_khám Bác_Sỹ chuyên_khoa thần_kinh\n",
            " Model Dịch:  dùng khoảng 300 đôla để làm cho người dân ở nhà của mình end  end end end end end end end end end end end end end end end end end end end end end tấtcả end end end\n",
            " BLEU Score:  0.0062\n",
            "\n",
            " Input (En):  eventually , after a period of six months of brutal war and a toll rate of almost 50,000 dead , we managed to liberate our country and to topple the tyrant .\n",
            " Target (Vi): Cuối_cùng thì , sau 6 tháng chiến_tranh ác_liệt với tổng thương_vong lên đến 50,000 người chúng_tôi đã xoay sở giải_phóng đất_nước mình và lật_đổ tên bạo_chúa .\n",
            " Model Dịch:  sau khoảng 15 tháng trước khi chiếntranh và giết chết người mỹ và những người chết đã chết đi bộ chết người mỹ đã mất đi hàng trăm triệu người end  end end end end end end end end\n",
            " BLEU Score:  0.0071\n",
            "\n",
            " Input (En):  &quot; before i die , i want to live off the grid . &quot;\n",
            " Target (Vi): & quot ; Trước khi tôi chết , tôi muốn sống ngoài khuôn_phép . & quot ;\n",
            " Model Dịch:  quot trước khi tôi đi xa khỏi những con đường mà tôi muốn gọi là quot end  quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot\n",
            " BLEU Score:  0.0157\n",
            "\n",
            " Input (En):  under the taliban , girls who went to school numbered in the hundreds -- remember , it was illegal .\n",
            " Target (Vi): Dưới Taliban , những cô gái đến trường cả hàng trăm người nhớ rằng , đó là bất_hợp_pháp .\n",
            " Model Dịch:  [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] end  đó end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  you never arrive in a community with any ideas , and you sit with the local people .\n",
            " Target (Vi): Đừng bao_giờ mang đến một cộng_đồng với những ý_tưởng , bạn ngồi với người bản_địa .\n",
            " Model Dịch:  bạn không baogiờ được cho là một trong những người thamgia và bạn đã từng gặp những người bạn end  end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0067\n",
            "\n",
            " Input (En):  and we could not believe , and we were telling the zambians , &quot; look how easy agriculture is . &quot;\n",
            " Target (Vi): Thật khó tin , và chúng_tôi nói với những người Zambia , & quot ; Mọi người xem trồng_trọt có đễ dàng không này . & quot ;\n",
            " Model Dịch:  và chúngta cóthể không tin vào và chúngta đang nói về những gì chúngta đang làm và [UNK] [UNK] quot end  quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot\n",
            " BLEU Score:  0.0077\n",
            "\n",
            " Input (En):  they kill our livestock .\n",
            " Target (Vi): Chúng giết gia_súc của chúng_tôi .\n",
            " Model Dịch:  họ giết chết end  end end end end end tấtcả end end end end end end tấtcả end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  the north korean authorities intercepted some money that i sent to my family , and , as a punishment , my family was going to be forcibly removed to a desolate location in the countryside .\n",
            " Target (Vi): Chính_quyền Bắc Triều_Tiên đã phát_hiện ra số tiền mà tôi gửi về cho gia_đình , và , để trừng_phạt , họ sẽ bắt gia_đình tôi phải chuyển về một vùng bị cách_ly ở nông_thôn .\n",
            " Model Dịch:  [UNK] [UNK] đã đưa cho tôi một người đànông đến [UNK] và họ đã có một giađình để bảovệ giađình mình và tôi đã có một người [UNK] trong một giađình nhỏ end  end end end end end end\n",
            " BLEU Score:  0.0080\n",
            "\n",
            " Input (En):  if , after this amazing list , they still are like , &quot; no , no , cameron , i want to be a model , &quot; well then i say , &quot; be my boss . &quot;\n",
            " Target (Vi): Nếu , sau một danh_sách thú_vị đó , các em vẫn nói rằng : & quot ; Không , không , Cameron , em muốn trở_thành người_mẫu à & quot ; , lúc đó tôi sẽ nói : & quot ; Làm sếp của chị đi & quot ; .\n",
            " Model Dịch:  nếu [UNK] nhưng nếu họ không thích nó thì tôi sẽ không có một cái gì đó tôi gọi là quot [UNK] quot end  quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot\n",
            " BLEU Score:  0.0131\n",
            "\n",
            " Input (En):  each has small , private rooms , where the slaves , women , along with young girls and boys , some as young as seven years old , are forced to entertain the clients , encouraging them to buy more food and alcohol .\n",
            " Target (Vi): Mỗi nơi có phòng riêng nhỏ , nơi các nô_lệ , phụ_nữ , cùng trẻ_em_trai và gái , một_số mới 7 tuổi , bị buộc giải_khuây cho khách_hàng , dụ họ mua thêm rượu và đồ ăn .\n",
            " Model Dịch:  mỗi trườnghọc có thunhập cao gấp đôi với những người phụnữ trẻ tuổi ở tuổi và các giáoviên trẻ tuổi tuổi teen và cô ấy đã thuê những người phụnữ trẻ tuổi tuổi bắtđầu bằng cách làmviệc với nhau end\n",
            " BLEU Score:  0.0069\n",
            "\n",
            " Input (En):  and after a while you are calling you , and you are calling you , and you have this great communication network .\n",
            " Target (Vi): Một lúc sau đó bạn gọi cho bạn , và bạn gọi cho bạn , và bạn sẽ có được mạng_lưới giao_tiếp rộng_lớn này .\n",
            " Model Dịch:  và sau khi bạn nhìn vào bạn và bạn biết đấy bạn là một người bạn của bạn và những người có quyềnlực end  end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0146\n",
            "\n",
            " Input (En):  so he jumps in and kills the animals .\n",
            " Target (Vi): Và rồi sư_tử nhảy vào và giết gia_súc .\n",
            " Model Dịch:  và ông ta đi ngủ và giết chết end  end end end end end end end end end end end end end end end đó end quot quot quot quot hết end end end đó end tấtcả end end\n",
            " BLEU Score:  0.0100\n",
            "\n",
            " Input (En):  and i &apos;ll tell you why .\n",
            " Target (Vi): Tôi sẽ nói cho bạn biết tại_sao .\n",
            " Model Dịch:  và tôi sẽ nói với bạn end  end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0111\n",
            "\n",
            " Input (En):  many women had children strapped to their backs while they were panning for gold , wading in water poisoned by mercury .\n",
            " Target (Vi): Nhiều phụ_nữ địu con trên lưng trong khi đãi vàng , và lội qua dòng nước nhiễm_độc thuỷ_ngân .\n",
            " Model Dịch:  nhiều người trong số họ ăn trưa với nhau như [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] end  end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  there she is .\n",
            " Target (Vi): Bà ấy đây .\n",
            " Model Dịch:  cô ấy có end  end end end end end end end end end end end end end end tấtcả hết end end end end end end end tấtcả end end end end end end end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  the shafts are up to 300 feet deep , and they carry out heavy bags of stone that later will be transported to another area , where the stone will be pounded so that they can extract the gold .\n",
            " Target (Vi): Những cái hầm sâu tới cả trăm mét , họ vác lên những chiếc túi đá nặng_trĩu để chuyển chúng tới khu_vực khác , nơi đá được nghiền ra để đãi lấy vàng .\n",
            " Model Dịch:  [UNK] [UNK] [UNK] [UNK] [UNK] và [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] và những thứ này end  end end đó end đó end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  in south asia , in countries like india and pakistan , four species of vultures are listed as critically endangered , which means they have less than 10 or 15 years to go extinct , and the reason is because they are falling prey by consuming livestock that has been treated with a painkilling drug like diclofenac .\n",
            " Target (Vi): Tại Nam_Á , những nước như Ấn_Độ và Pakistan , 4 loài kền_kền được ghi_danh trong danh_sách những có nguy_cơ_cực cao điều này có_nghĩa_là chúng chỉ còn ít hơn 10 hoặc 15 năm để chạm đến mức tuyệt_chủng và lí_do đó là bởi_vì chúng bị biến thành con mồi vì ăn phải gia_súc đã được chữa_trị bằng thuốc giảm đau như Diclofenac .\n",
            " Model Dịch:  Ở [UNK] ở ẤnĐộ và các nước giàu và những người nghèo nhất ở trungquốc cũng như những người sống trong những năm gần như là những người bìnhthường sống như những người bìnhthường sống như những người bìnhthường sống\n",
            " BLEU Score:  0.0046\n",
            "\n",
            " Input (En):  and the first idea i got was to use fire , because i thought lions were scared of fire .\n",
            " Target (Vi): Ý_tưởng đầu_tiên mà tôi có được là sử_dụng lửa , bởi_vì tôi nghĩ sư_tử sợ lửa .\n",
            " Model Dịch:  và điều đầutiên tôi thấy là tôi phải ăn thịt vì tôi nghĩ rằng những con chim end  end end end end end end end end end end end end end quot quot quot miễnphí end end end end\n",
            " BLEU Score:  0.0119\n",
            "\n",
            " Input (En):  i feel like every time someone sneezes , new orleans has a parade .\n",
            " Target (Vi): Tôi cảm_thấy giống mỗi lần ai đó hắt_xì , New_Orleans có cả một cuộc diễu_hành .\n",
            " Model Dịch:  tôi cảmthấy như là mỗi người đã từng có một người [UNK] [UNK] end  end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0062\n",
            "\n",
            " Input (En):  now , it was emotional and it was inspiring , and i &apos;ve always heard about thinking outside the box , but it wasn &apos;t until i had actually gotten outside of my box that something happened .\n",
            " Target (Vi): Thật xúc_động và háo_hức . Trước đó , tôi từng nghe nói phải nghĩ thoáng ra ngoài khuôn_khổ , nhưng chỉ khi tôi thực_sự trải nghiệm điều đó điều ký diệu mới xảy ra .\n",
            " Model Dịch:  bâygiờ là sự imlặng và tôi cảmthấy là tôi đã nghe những điều này nhưng tôi không nói với bạn rằng nó đang ở trong một cái hộp nhỏ và tôi đã nói rằng nó sẽ xảy ra với những\n",
            " BLEU Score:  0.0142\n",
            "\n",
            " Input (En):  but i &apos;m also happy and honored to be up here and i think that it &apos;s great that i got to come before 10 or 20 or 30 years had passed and i &apos;d had more agency in my career , because maybe then i wouldn &apos;t tell the story of how i got my first job , or maybe i wouldn &apos;t tell the story of how i paid for college , which seems so important right now .\n",
            " Target (Vi): Nhưng tôi cũng là vui_mừng và vinh_dự lên đây tôi nghĩ rằng nó là may_mắn là tôi đã đến trước khi 10 , 20 hay 30 năm trôi qua và tôi đã từng làm_việc với nhiều công_ty trong sự_nghiệp của mình , bởi_vì khi đó tôi có_thể sẽ không_thể kể chuyện làm thế_nào tôi có công_việc đầu_tiên , hay có_lẽ tôi sẽ không nói ra chuyện về làm thế_nào tôi có tiền đóng học_phí , mà có vẻ quan_trọng như_vậy ngay lúc này .\n",
            " Model Dịch:  nhưng tôi rất vui và tôi đã rất vui và tôi đã nói là tôi đã có 20 năm trước đây là một ngày cho đến năm 2000 bạn sẽ không baogiờ đi vào tươnglai của mình để làm cho\n",
            " BLEU Score:  0.0196\n",
            "\n",
            " Input (En):  i met conor on a cold , rainy january night .\n",
            " Target (Vi): Tôi đã gặp Conor trong một đêm tháng_một , mưa và lạnh .\n",
            " Model Dịch:  tôi đã gặp một đêm nhảy vào mùa hè [UNK] end  end end end end end end end end end đó end tấtcả end end end end tấtcả end end end end end end end end end tấtcả end\n",
            " BLEU Score:  0.0142\n",
            "\n",
            " Input (En):  because you can see where i am , where i sleep at night , what i am doing .\n",
            " Target (Vi): Bởi_vì tôi có_thể thấy những nơi tôi đã đến đó , nơi tôi ngủ mỗi đêm , những việc tôi đã làm .\n",
            " Model Dịch:  vì bạn cóthể thấy tôi đang ở đâu khi tôi đang ở đâu tôi đã làm được end  end đó quot quot end end quot quot quot quot quot quot end end end đó end đó end quot quot\n",
            " BLEU Score:  0.0290\n",
            "\n",
            " Input (En):  i always wondered why they had lights but we didn &apos;t .\n",
            " Target (Vi): Tôi lúc_nào cũng tự hỏi là tại_sao họ lại có điện còn chúng_tôi thì không .\n",
            " Model Dịch:  tôi luôn bănkhoăn không nhưng họ làm gì end  end end end end end end end end end end quot quot quot quot quot quot quot quot quot end end end cả end end end end end đó hết\n",
            " BLEU Score:  0.0056\n",
            "\n",
            " Input (En):  &quot; oh , no , i cannot do this . &quot; &quot; would you like me to find you somebody ? &quot;\n",
            " Target (Vi): & quot ; Oh , không , tôi không_thể làm được điều này . & quot ; Bạn có muốn tôi tìm ai khác cho bạn không ? & quot ;\n",
            " Model Dịch:  quot không tôi không chắc rằng nếu bạn sẽ tìm được người khác quot end  quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot\n",
            " BLEU Score:  0.0084\n",
            "\n",
            " Input (En):  the first principle of aid is respect .\n",
            " Target (Vi): Nguyên_tắc đầu_tiên về viện_trợ là tôn_trọng .\n",
            " Model Dịch:  nguyêntắc thứ nhất của sự quantâm của đạođức end  end end end end end end end end end end end end end end end end tấtcả end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0000\n",
            "\n",
            " Input (En):  i have witnessed my garden become a tool for the education , a tool for the transformation of my neighborhood .\n",
            " Target (Vi): Tôi đã chứng_kiến mảnh vườn của mình trở_thành một công_cụ giáo_dục , một công_cụ cho sự chuyển_đổi của vùng_đất tôi sống .\n",
            " Model Dịch:  tôi đã nhận ra rằng tôi là một côngcụ để trởthành một côngcụ cho sứckhoẻ cộngđồng của tôi end  đó end đó end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0074\n",
            "\n",
            " Input (En):  but many die .\n",
            " Target (Vi): Nhưng rất nhiều người đã chết .\n",
            " Model Dịch:  nhưng rất nhiều end  end end end end end end end tấtcả end end end end end end end end end end end tấtcả end end end end end end end end end end end end end  end\n",
            " BLEU Score:  0.0103\n",
            "\n",
            " Input (En):  induction can heat , especially steel ; it &apos;s very good at that .\n",
            " Target (Vi): Cảm_ứng từ có_thể tạo nhiệt , đặc_biệt thép lại dẫn_nhiệt rất tốt .\n",
            " Model Dịch:  [UNK] cóthể là những cái [UNK] nhỏ rất đẹp end  end end end end end end end end tấtcả end end end end end tấtcả end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  the funny thing about sustainability , you have to sustain it .\n",
            " Target (Vi): Điều thú_vị về sự bền_vững , đó là bạn phải duy_trì nó .\n",
            " Model Dịch:  Điều thúvị là bạn phải làm điều đó để làm điều đó end  end end end end end end end end tấtcả end tấtcả end tấtcả end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0267\n",
            "\n",
            " Input (En):  wrong . they were all enslaved .\n",
            " Target (Vi): Sai . Họ đều bị nô_lệ .\n",
            " Model Dịch:  Đúng không may là họ đã từng là những kẻ [UNK] end  end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0000\n",
            "\n",
            " Input (En):  so at the end , i had a settlement with them .\n",
            " Target (Vi): Và cuối_cùng , tôi đã có một thoả_thuận với họ .\n",
            " Model Dịch:  cuốicùng tôi đã có một cái bẫy cho những người này end  end end đó end end quot quot quot quot quot quot quot quot quot quot end end đó end đó end đó end đó end end đó\n",
            " BLEU Score:  0.0590\n",
            "\n",
            " Input (En):  i could get them in a worse situation than they were already in .\n",
            " Target (Vi): Tôi có_thể đưa họ vào tình_cảnh tệ hơn hiện_tại của họ .\n",
            " Model Dịch:  tôi cóthể thấy chúng ở trong hơn ít hơn end  end end end end end end end end end end end end end end end end end end end end end end tấtcả end end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  my secret was that i had this gun loaded with hollow-point bullets pointed at my head by the man who i thought was my soulmate , many , many times .\n",
            " Target (Vi): Bí_mật đó là , cây súng này được nạp sẵn đạn hollow - point chỉa thẳng vào đầu tôi bởi người đàn_ông tôi đã nghĩ là người bạn_đời , từ lần này qua lần khác .\n",
            " Model Dịch:  bímật của tôi là tôi có được [UNK] [UNK] của mình vì tôi nghĩ rằng tôi đang ở trong một buổi lễ [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] end  đó end đó end end end end tấtcả end end\n",
            " BLEU Score:  0.0074\n",
            "\n",
            " Input (En):  i want to change that perception . i want to change those feelings you have for these birds , because they need our sympathy . they really do .\n",
            " Target (Vi): Tôi muốn thay_đổi sự nhận_thức đó . Tôi muốn thay_đổi những cảm_giác mà bạn dành cho những chú chim này , vì chúng cần đến sự thương_cảm của chúng_ta . Chúng thật_sự rất cần .\n",
            " Model Dịch:  tôi muốn thayđổi cách thayđổi tôi muốn thayđổi những điều mà mọi người đều cảmthấy xấuhổ vì họ muốn có những người khác end  end end đó end đó end end tấtcả end end tấtcả end end tấtcả end\n",
            " BLEU Score:  0.0077\n",
            "\n",
            " Input (En):  we want self-determination in the digital age , and we don &apos;t want that phone companies and internet companies have to store all this information about us .\n",
            " Target (Vi): Chúng_tôi muốn có được sự tự_chủ trong thời_đại công_nghệ số , và chúng_tôi không muốn rằng các công_ty viễn_thông và nhà cung_cấp dịch_vụ Internet lưu_trữ lại tất_cả các thông_tin của mình .\n",
            " Model Dịch:  chúngta muốn các côngty internet và internet không phải là dữliệu mà chúngtôi đã làm là chúngtôi có tiền và nănglượng mà bạn đang làm trong côngty end  end end end end end end end end end end tấtcả\n",
            " BLEU Score:  0.0077\n",
            "\n",
            " Input (En):  potholes , of course , that can become a problem , but we have a solution .\n",
            " Target (Vi): Ổ_gà , đương_nhiên , có_thể trở_thành một vấn_đề , Nhưng chúng_tôi có giải_pháp .\n",
            " Model Dịch:  [UNK] tấtnhiên là chúngta cóthể làm một vấnđề nhưng vấnđề là một vấnđề end  end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0047\n",
            "\n",
            " Input (En):  together we can make our beds , our dinner tables and our families the safe and peaceful oases they should be .\n",
            " Target (Vi): Cùng nhau chúng_ta có_thể làm cho giường ngủ của chúng_ta bàn ăn và gia_đình của chúng_ta trở_nên những ốc_đảo bình_yên và an_toàn\n",
            " Model Dịch:  cùng với chúngta cùng với những người tôi đang làm với vợ mình và họ đang ngồi trên ghế sofa và họ sẽ đưa cho các nhà cungcấp cho người dân end  end end end end end end end\n",
            " BLEU Score:  0.0071\n",
            "\n",
            " Input (En):  thinking about death clarifies your life .\n",
            " Target (Vi): Suy_nghĩ về cái chết làm cuộc_sống của bạn rõ_ràng .\n",
            " Model Dịch:  nghĩ về sự sống trong cuộcsống của mình end  end end end end end end end tấtcả hết end end end end tấtcả end end end end end end end end tấtcả end end end end end end end\n",
            " BLEU Score:  0.0056\n",
            "\n",
            " Input (En):  death is something that we &apos;re often discouraged to talk about or even think about , but i &apos;ve realized that preparing for death is one of the most empowering things you can do .\n",
            " Target (Vi): Cái chết là một cái gì đó chúng_ta thường không được khuyến_khích để nói đến hoặc thậm_chí là nghĩ đến , nhưng tôi đã đang nhận ra rằng chuẩn_bị cho cái chết là một trong những điều quyền_lực nhất bạn có_thể làm .\n",
            " Model Dịch:  Điều đó là điều tốt nhất mà chúngta từng nghĩ đến là vì chúngta đã nghĩ rằng đó là lýdo tạisao tôi lại bị mất đi khi đó là một cuộc đua maratông nơi mà bạn cóthể làm cho nó\n",
            " BLEU Score:  0.0178\n",
            "\n",
            " Input (En):  local , passionate people . that &apos;s who you have applauded .\n",
            " Target (Vi): Người bản_địa , những con_người khát_khao . Đó là những người bạn đã vỗ_tay tán_thưởng .\n",
            " Model Dịch:  những người lãnhđạo người anh ấy là những người bạn của họ end  end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0624\n",
            "\n",
            " Input (En):  she also had duplicates .\n",
            " Target (Vi): Cô cũng đã có bản_sao của bức ảnh .\n",
            " Model Dịch:  cô ấy cũng có được [UNK] end  end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0056\n",
            "\n",
            " Input (En):  so we still have the specimen here . it &apos;s quite warm .\n",
            " Target (Vi): Chúng_tôi còn vật mẫu ở đây . Nó còn khá ấm .\n",
            " Model Dịch:  chúngtôi vẫn có những [UNK] rất lớn end  end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
            " BLEU Score:  0.0000\n",
            "\n",
            " Input (En):  that &apos;s enough space to plant 725 million tomato plants .\n",
            " Target (Vi): đủ để trồng 725 triệu cây cà_chua .\n",
            " Model Dịch:  Đó là một [UNK] để trồng rừng ở những nơi khác nhau end  end end end end end end end end end end end end end end end end end tấtcả end end end end end end end end\n",
            " BLEU Score:  0.0100\n",
            "\n",
            " Input (En):  when i was little , i thought my country was the best on the planet , and i grew up singing a song called &quot; nothing to envy . &quot;\n",
            " Target (Vi): Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất_nước tốt nhất trên thế_giới và tôi thường hát bài & quot ; Chúng_ta chẳng có gì phải ghen_tị . & quot ;\n",
            " Model Dịch:  khi tôi lớn lên tôi nghĩ là tôi đang đứng trên sânkhấu và tôi nghĩ rằng quot [UNK] [UNK] quot là những gì không có những truyềnthuyết về thếgiới quot end  quot quot quot quot quot quot quot quot\n",
            " BLEU Score:  0.0183\n",
            "\n",
            "------------------------------------------------\n",
            "ĐIỂM BLEU TRUNG BÌNH (50 mẫu): 0.0119\n"
          ]
        }
      ]
    }
  ]
}